{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with Different Features ( multiple number)\n",
    "\n",
    "**Name**: ZHU GUANGYU  \n",
    "**Student ID**: 20165953  \n",
    "**Github Repo**: [assignment10](https://github.com/z1ggy-o/cv_assignment/tree/master/assignment10)  \n",
    "\n",
    "---\n",
    "\n",
    "In a *classification problem*, the outcome  takes on only a finit number of values. In the simplest case, outcome has only two values, for example TRUE or FALSE. This is called the *binary classification problem*.\n",
    "\n",
    "As in real-valued data fitting, we assume that an approxomate relation ship of the form $y \\approx f(x)$ holds, where $f: R^{n} \\rightarrow {-1, +1}$. The model $\\hat{f}$ is called a *classifier*.\n",
    "\n",
    "For a given data point x, y with predicted outcome $\\hat{y} = \\hat{f}(x)$, there are four possibilities:\n",
    "\n",
    "- *True positive*: $y = +1$ and $\\hat{y} = +1$.\n",
    "- *True negative*: $y = -1$ and $\\hat{y} = -1$.\n",
    "- *False positive*: $y = -1$ and $\\hat{y} = +1$.\n",
    "- *False negative*: $y = +1$ and $\\hat{y} = -1$.\n",
    "\n",
    "---\n",
    "\n",
    "Continue ï½—ith assignmen09, this time we use *least squares classifer* to build classifiers for each number in MNIST data set. \n",
    "\n",
    "We still use feature functions $f_{i} = r_{i}^{T}x, r_{i} \\sim N(0, \\sigma)$, and try with varing the number of parameter $p$ with the standard deviation $\\sigma = 1$ of the random feature vectore $r$.\n",
    "\n",
    "Since this time we want to do the classification for ten numbers, our sign function is change to:\n",
    "$$ argmax_{n} \\tilde{f}_{n}(x)$$\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classifier\n",
    "\n",
    "### Import data set\n",
    "\n",
    "We have two data sets, one for training, one for testing. Each element is a image that has height 28 and width 28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_data_train = \"mnist_train.csv\"\n",
    "file_data_test  = \"mnist_test.csv\"\n",
    "\n",
    "h_data_train    = open(file_data_train, \"r\")\n",
    "h_data_test     = open(file_data_test, \"r\")\n",
    "\n",
    "data_train      = h_data_train.readlines()\n",
    "data_test       = h_data_test.readlines()\n",
    "\n",
    "h_data_train.close()\n",
    "h_data_test.close()\n",
    "\n",
    "size_row    = 28    # height of the image\n",
    "size_col    = 28    # width of the image\n",
    "\n",
    "num_train   = len(data_train)   # number of training images\n",
    "num_test    = len(data_test)    # number of testing images\n",
    "\n",
    "# number of training images: 60000\n",
    "# number of testing images: 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the bias, we need to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# normalize the values of the input data to be [0, 1]\n",
    "#\n",
    "def normalize(data):\n",
    "\n",
    "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
    "\n",
    "    return(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize each pixel, and put image data into a $784*num\\_image$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# make a matrix each column of which represents an images in a vector form \n",
    "#\n",
    "list_image_train    = np.empty((size_row * size_col, num_train), dtype=float)  # 784 * num_trian matrix\n",
    "list_label_train    = np.empty(num_train, dtype=int)\n",
    "\n",
    "list_image_test     = np.empty((size_row * size_col, num_test), dtype=float)\n",
    "list_label_test     = np.empty(num_test, dtype=int)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for line in data_train:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])  # convert to float type\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_label_train[count]     = label\n",
    "    list_image_train[:, count]  = im_vector  # each column is a image\n",
    "\n",
    "    count += 1\n",
    "\n",
    "count = 0\n",
    "\n",
    "for line in data_test:\n",
    "\n",
    "    line_data   = line.split(',')\n",
    "    label       = line_data[0]\n",
    "    im_vector   = np.asfarray(line_data[1:])\n",
    "    im_vector   = normalize(im_vector)\n",
    "\n",
    "    list_label_test[count]      = label\n",
    "    list_image_test[:, count]   = im_vector    \n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature functions generator\n",
    "\n",
    "Depends on the given number of parameters we should generate correponde feature functions $r$. Each element of $r$ is a vector with length $28 * 28$. The element of $r_{i}$ is random number from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(n, size):\n",
    "    \"\"\"Generate feature functions\n",
    "    \n",
    "    Argumengs:\n",
    "        n(int): number of parameters\n",
    "        size: number of elements of each vector\n",
    "    Return:\n",
    "        functions(2d matrix): feature function matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    functions = []\n",
    "    \n",
    "    # for n, generate vectore with #size elements\n",
    "    mean, sigma = 0, 1\n",
    "    \n",
    "    for _ in range(n):\n",
    "        ri = np.random.normal(mean, sigma, size)\n",
    "        functions.append(ri)\n",
    "    \n",
    "    return np.array(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the matrix of feature funtions and data\n",
    "\n",
    "Since we have got feature functions, now we can apply them on input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tilde_matrix(feature_func, data, num_data):\n",
    "    \"\"\"Create matrix of feature function on data\n",
    "    \n",
    "    Arguments:\n",
    "        feature_func(2d matrix): feature function matrix\n",
    "        data: input image data\n",
    "        num_data: number of input data\n",
    "    Return:\n",
    "        matrix of feature functions applied on image data\n",
    "    \"\"\"\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    for i in range(num_data):\n",
    "        img = data[:, i]  # ith image(column)\n",
    "        row = np.inner(feature_func, img)\n",
    "        A.append(row)\n",
    "    \n",
    "    return np.array(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute each number's $\\theta_{n}$\n",
    "\n",
    "For computing, we need to process label $y$ which gives correspond number's image $+1$ and other number's image $-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process label array\n",
    "def process_label(labels, number):\n",
    "    result = []\n",
    "    for label in labels:\n",
    "        if label == number:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depends on $A\\theta = y$, while $A$ is the matrix of feature function apply on data set, $\\theta$ is perameters, and $y$ is the label.\n",
    "\n",
    "Through pseudo inverse $(A^{T}A)^{-1}A$ we can compute the $\\theta$. Here we use `np.linalg.pinv` to get $A^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_theta(A, y):\n",
    "    A_inv = np.linalg.pinv(A)\n",
    "    theta = np.inner(A_inv, y)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we need to which label is the best result for current number image, we need each number's parameter to do the comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_thetas(A, image_labels):\n",
    "    \"\"\"Compute parameters for each number\n",
    "    \n",
    "    Generate correspond label list, then use it to compute theta.\n",
    "    \n",
    "    Argument:\n",
    "        A(2d matrix): tilde matrix of feature funcion on input images\n",
    "    Return:\n",
    "        A list of parameters. Index correspond to number label.\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        label_processed = process_label(image_labels, i)\n",
    "        theta = compute_theta(A, label_processed)\n",
    "        parameters.append(theta)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classifier $\\hat{f}(x)$\n",
    "\n",
    "Now we have had feature functions, parameters, so we can create our classifier\n",
    "$\\hat{f}(x) = argmax_{n}(\\tilde{f}_{n}(x))$, where\n",
    "$\\tilde{f}(x) = \\theta_{1}f_{1}(x) + \\theta_{2}f_{2}(x) + \\cdots + \\theta_{p}f_{p}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(A, parameters, num_images):\n",
    "    \"\"\"Give back maximum argument's label\n",
    "    \n",
    "    Arguments:\n",
    "        A(2d matrix): tilde matrix of feature function on input images\n",
    "        parameters(list): list of parameters of each number image\n",
    "    Return:\n",
    "        prediction label of images\n",
    "    \"\"\"\n",
    "    tilde_all = []\n",
    "    \n",
    "    # compute each images's tilde value correspond to diff parameter\n",
    "    for parameter in parameters:\n",
    "        f_tilde_n = np.inner(A, np.array(parameter))\n",
    "        tilde_all.append(f_tilde_n)\n",
    "    \n",
    "    tilde_all = np.array(tilde_all)\n",
    "    \n",
    "    result = []\n",
    "    # find maximum tilde value for each image\n",
    "    # let its label be images's prediction\n",
    "    for i in range(num_images):\n",
    "        value_i = tilde_all[:, i]\n",
    "        label = np.argmax(value_i)\n",
    "        result.append(label)\n",
    "        \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Confusion Matrix and $F_{1}$ Scores\n",
    "\n",
    "### Create confusion matrix\n",
    "\n",
    "Let row of matrix be digits, column be the number of correspond predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(test_labels, predictions):\n",
    "    \"\"\"Build confusion matrix\n",
    "    \n",
    "    Matrix that indicates the number of classification for the digit\n",
    "    \n",
    "    Argument:\n",
    "        test_labels(1d array): correct label of input images\n",
    "        predictions(1d array): predicted label of input images\n",
    "    Return:\n",
    "        2d matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix = np.zeros((10, 10), dtype=int)  # there are ten numbers\n",
    "    \n",
    "    length = len(test_labels)\n",
    "    for i in range(length):\n",
    "        matrix[test_labels[i]][predictions[i]] += 1\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute $F_{1}$ scores\n",
    "\n",
    "$$F_{1} score = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall},$$\n",
    "\n",
    "where $precision = \\frac{true \\ positives}{true \\ positives \\ + \\ false \\ positives}$, $recall = \\frac{true \\ positives}{false \\ negative \\ + \\ true \\ positive}$\n",
    "\n",
    "We compute each number's $F_{1}$ score then use their average value as finial score for current number of parameters.\n",
    "\n",
    "From confusion matrix $M$, we can tell, for each index $i$:\n",
    "\n",
    "- $M[i][i]$ is the True Positive of number $i$,\n",
    "- sum of $row[i]$ is True Posive adds False Nagetive\n",
    "- sum of $column[i]$ is True Posive adds False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(M):\n",
    "    \n",
    "    f1_scores = []\n",
    "    \n",
    "    for i in range(10):  # there are ten numbers\n",
    "        tp = M[i][i]\n",
    "        fn = sum(M[i]) - tp\n",
    "        fp = sum(M[:, i]) - tp\n",
    "        f1_scores.append(compute_f1(tp, fn, fp))\n",
    "    \n",
    "    return sum(f1_scores) / 10\n",
    "\n",
    "\n",
    "def compute_f1(tp, fn, fp):\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (fn + tp)\n",
    "    \n",
    "    return 2*precision*recall / (precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all parts together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificate(p,\n",
    "                 image_train, num_trian, labels_train,\n",
    "                 image_test, num_test, labels_test):\n",
    "    \n",
    "    size_img = 28 * 28\n",
    "    \n",
    "    # generate features\n",
    "    r = generate_features(p, size_img)\n",
    "    \n",
    "    # generate training img tilde matrix\n",
    "    A_train = generate_tilde_matrix(r, image_train, num_train)\n",
    "    \n",
    "    # compute parameters\n",
    "    parameters = compute_all_thetas(A_train, labels_train)\n",
    "    \n",
    "    # generate testing img tilde matrix\n",
    "    A_test = generate_tilde_matrix(r, image_test, num_test)\n",
    "    \n",
    "    # get predictions\n",
    "    predictions = argmax(A_test, parameters, num_test)\n",
    "    \n",
    "    # generate confusion matrix\n",
    "    confusion = create_confusion_matrix(labels_test, predictions)\n",
    "    \n",
    "    # compute F1 score\n",
    "    f1 = get_f1(confusion)\n",
    "    \n",
    "    return confusion, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test With Different $p$\n",
    "\n",
    "Now let's try different number of parameters to see how $F_{1}$ score changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for present results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def print_table(M):\n",
    "    totals = []\n",
    "    table = PrettyTable()\n",
    "\n",
    "    table.add_column(\" \", [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    for i in range(10):\n",
    "        totals.append(sum(M[i]))\n",
    "        table.add_column(str(i), M[:,i].flatten())  \n",
    "    table.add_column(\"Total\", totals)\n",
    "    \n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different number of parameters\n",
    "\n",
    "Now let's try different number parameters.\n",
    "\n",
    "Here we use logarithm $2^{n}, n \\in [1, 10]$ number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziggy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Table with 2 parameters\n",
      "+---+-----+-----+---+---+----+---+---+-----+---+---+-------+\n",
      "|   |  0  |  1  | 2 | 3 | 4  | 5 | 6 |  7  | 8 | 9 | Total |\n",
      "+---+-----+-----+---+---+----+---+---+-----+---+---+-------+\n",
      "| 0 | 209 | 178 | 0 | 0 | 2  | 0 | 0 | 591 | 0 | 0 |  980  |\n",
      "| 1 | 433 | 207 | 0 | 1 | 48 | 0 | 0 | 446 | 0 | 0 |  1135 |\n",
      "| 2 | 200 | 131 | 0 | 0 | 26 | 0 | 0 | 675 | 0 | 0 |  1032 |\n",
      "| 3 | 208 | 218 | 0 | 2 | 71 | 0 | 0 | 511 | 0 | 0 |  1010 |\n",
      "| 4 | 103 |  24 | 0 | 0 | 61 | 0 | 0 | 794 | 0 | 0 |  982  |\n",
      "| 5 | 208 | 166 | 0 | 2 | 18 | 0 | 0 | 498 | 0 | 0 |  892  |\n",
      "| 6 | 106 |  25 | 0 | 0 | 10 | 0 | 0 | 817 | 0 | 0 |  958  |\n",
      "| 7 | 152 |  30 | 0 | 0 | 2  | 0 | 0 | 844 | 0 | 0 |  1028 |\n",
      "| 8 | 310 | 177 | 0 | 1 | 14 | 0 | 0 | 472 | 0 | 0 |  974  |\n",
      "| 9 | 151 |  18 | 0 | 0 | 21 | 0 | 0 | 819 | 0 | 0 |  1009 |\n",
      "+---+-----+-----+---+---+----+---+---+-----+---+---+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 4 parameters\n",
      "+---+-----+-----+-----+----+-----+-----+-----+-----+----+---+-------+\n",
      "|   |  0  |  1  |  2  | 3  |  4  |  5  |  6  |  7  | 8  | 9 | Total |\n",
      "+---+-----+-----+-----+----+-----+-----+-----+-----+----+---+-------+\n",
      "| 0 | 304 |  66 |  97 | 48 |  62 |  23 | 164 | 205 | 4  | 7 |  980  |\n",
      "| 1 |  3  | 902 |  88 | 1  |  39 |  60 |  13 |  18 | 10 | 1 |  1135 |\n",
      "| 2 |  67 |  66 | 421 | 13 | 197 |  6  | 157 |  94 | 8  | 3 |  1032 |\n",
      "| 3 | 195 | 109 | 214 | 42 | 115 |  65 | 171 |  92 | 4  | 3 |  1010 |\n",
      "| 4 |  21 |  74 | 168 | 8  | 469 |  50 | 141 |  36 | 8  | 7 |  982  |\n",
      "| 5 | 120 | 106 |  62 | 30 | 168 | 134 | 180 |  86 | 3  | 3 |  892  |\n",
      "| 6 |  77 |  48 | 168 | 21 | 102 |  28 | 449 |  51 | 9  | 5 |  958  |\n",
      "| 7 | 249 |  68 | 165 | 4  |  47 |  59 | 149 | 279 | 7  | 1 |  1028 |\n",
      "| 8 |  31 | 304 | 161 | 17 | 251 |  17 |  93 |  61 | 31 | 8 |  974  |\n",
      "| 9 |  36 | 246 | 158 | 3  | 257 |  89 |  98 |  81 | 32 | 9 |  1009 |\n",
      "+---+-----+-----+-----+----+-----+-----+-----+-----+----+---+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 8 parameters\n",
      "+---+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1  |  2  |  3  |  4  | 5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-------+\n",
      "| 0 | 135 | 200 |  74 | 171 |  30 | 2  | 194 |  20 | 146 |  8  |  980  |\n",
      "| 1 |  22 | 961 |  53 |  37 |  0  | 2  |  25 |  1  |  34 |  0  |  1135 |\n",
      "| 2 |  29 | 125 | 339 | 171 | 124 | 1  |  97 |  20 | 110 |  16 |  1032 |\n",
      "| 3 |  23 |  88 |  66 | 630 |  15 | 3  | 139 |  9  |  33 |  4  |  1010 |\n",
      "| 4 |  15 |  15 |  72 |  12 | 620 | 1  |  68 |  93 |  18 |  68 |  982  |\n",
      "| 5 |  72 | 137 |  16 | 148 |  39 | 47 | 159 | 101 | 165 |  8  |  892  |\n",
      "| 6 |  15 |  41 |  58 |  20 |  39 | 0  | 740 |  32 |  11 |  2  |  958  |\n",
      "| 7 |  19 |  94 | 112 |  8  | 166 | 1  | 101 | 445 |  42 |  40 |  1028 |\n",
      "| 8 |  50 |  97 |  90 |  80 |  63 | 3  | 163 |  59 | 347 |  22 |  974  |\n",
      "| 9 |  23 |  31 |  82 |  14 | 457 | 0  |  74 |  77 |  48 | 203 |  1009 |\n",
      "+---+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 16 parameters\n",
      "+---+-----+------+-----+-----+-----+----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1   |  2  |  3  |  4  | 5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+------+-----+-----+-----+----+-----+-----+-----+-----+-------+\n",
      "| 0 | 862 |  2   |  39 |  22 |  1  | 2  |  16 |  4  |  32 |  0  |  980  |\n",
      "| 1 |  0  | 1091 |  2  |  6  |  7  | 1  |  4  |  9  |  15 |  0  |  1135 |\n",
      "| 2 |  77 | 160  | 540 |  48 |  27 | 2  |  56 |  33 |  69 |  20 |  1032 |\n",
      "| 3 |  55 |  82  |  19 | 696 |  24 | 7  |  35 |  20 |  56 |  16 |  1010 |\n",
      "| 4 |  41 |  85  |  52 |  15 | 587 | 1  |  49 |  56 |  32 |  64 |  982  |\n",
      "| 5 | 142 |  96  |  39 | 277 |  84 | 48 |  43 |  21 | 122 |  20 |  892  |\n",
      "| 6 | 176 |  39  |  63 |  48 |  78 | 3  | 504 |  13 |  25 |  9  |  958  |\n",
      "| 7 | 117 | 157  |  26 |  29 |  63 | 1  |  33 | 472 |  59 |  71 |  1028 |\n",
      "| 8 |  52 |  80  |  49 | 145 |  62 | 4  |  25 |  21 | 517 |  19 |  974  |\n",
      "| 9 |  65 |  95  |  50 |  38 | 170 | 0  |  37 | 111 |  43 | 400 |  1009 |\n",
      "+---+-----+------+-----+-----+-----+----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 32 parameters\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1   |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "| 0 | 894 |  5   |  5  |  14 |  6  |  9  |  25 |  10 |  12 |  0  |  980  |\n",
      "| 1 |  0  | 1081 |  27 |  4  |  1  |  0  |  9  |  4  |  6  |  3  |  1135 |\n",
      "| 2 |  18 | 109  | 709 |  53 |  22 |  0  |  51 |  22 |  40 |  8  |  1032 |\n",
      "| 3 |  8  |  42  |  38 | 786 |  9  |  25 |  34 |  26 |  23 |  19 |  1010 |\n",
      "| 4 |  12 |  38  |  25 |  36 | 648 |  1  |  44 |  55 |  12 | 111 |  982  |\n",
      "| 5 | 169 |  60  |  21 | 109 |  29 | 219 |  81 |  77 |  94 |  33 |  892  |\n",
      "| 6 |  62 |  31  |  29 |  8  |  40 |  11 | 772 |  0  |  3  |  2  |  958  |\n",
      "| 7 |  17 |  43  |  33 |  38 |  19 |  8  |  3  | 826 |  10 |  31 |  1028 |\n",
      "| 8 |  25 | 140  |  21 | 127 |  18 |  23 |  36 |  34 | 527 |  23 |  974  |\n",
      "| 9 |  30 |  30  |  23 |  47 |  74 |  3  |  8  | 122 |  15 | 657 |  1009 |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 64 parameters\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1   |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "| 0 | 923 |  0   |  9  |  3  |  0  |  3  |  27 |  2  |  13 |  0  |  980  |\n",
      "| 1 |  1  | 1078 |  8  |  11 |  1  |  2  |  9  |  3  |  22 |  0  |  1135 |\n",
      "| 2 |  30 |  95  | 740 |  38 |  21 |  2  |  30 |  26 |  43 |  7  |  1032 |\n",
      "| 3 |  10 |  33  |  38 | 806 |  3  |  28 |  15 |  41 |  20 |  16 |  1010 |\n",
      "| 4 |  3  |  39  |  14 |  3  | 767 |  3  |  27 |  8  |  23 |  95 |  982  |\n",
      "| 5 |  34 |  16  |  13 | 120 |  22 | 508 |  46 |  41 |  67 |  25 |  892  |\n",
      "| 6 |  25 |  14  |  17 |  1  |  30 |  8  | 857 |  1  |  3  |  2  |  958  |\n",
      "| 7 |  6  |  48  |  23 |  5  |  21 |  0  |  2  | 871 |  13 |  39 |  1028 |\n",
      "| 8 |  25 |  78  |  29 |  56 |  19 |  28 |  35 |  43 | 626 |  35 |  974  |\n",
      "| 9 |  20 |  19  |  10 |  14 |  93 |  8  |  2  |  91 |  24 | 728 |  1009 |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 128 parameters\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1   |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "| 0 | 934 |  1   |  3  |  3  |  2  |  8  |  18 |  3  |  7  |  1  |  980  |\n",
      "| 1 |  0  | 1093 |  5  |  5  |  1  |  0  |  6  |  2  |  23 |  0  |  1135 |\n",
      "| 2 |  20 |  62  | 820 |  20 |  14 |  1  |  27 |  23 |  37 |  8  |  1032 |\n",
      "| 3 |  7  |  19  |  25 | 861 |  4  |  18 |  12 |  27 |  22 |  15 |  1010 |\n",
      "| 4 |  1  |  25  |  10 |  1  | 860 |  2  |  12 |  3  |  14 |  54 |  982  |\n",
      "| 5 |  28 |  13  |  11 |  99 |  24 | 564 |  33 |  22 |  73 |  25 |  892  |\n",
      "| 6 |  20 |  11  |  12 |  0  |  16 |  13 | 880 |  0  |  6  |  0  |  958  |\n",
      "| 7 |  4  |  42  |  19 |  11 |  16 |  0  |  3  | 877 |  6  |  50 |  1028 |\n",
      "| 8 |  15 |  55  |  12 |  39 |  20 |  37 |  20 |  22 | 734 |  20 |  974  |\n",
      "| 9 |  19 |  14  |  9  |  14 |  59 |  4  |  4  |  70 |  14 | 802 |  1009 |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 256 parameters\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1   |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "| 0 | 937 |  0   |  4  |  3  |  1  |  7  |  18 |  1  |  8  |  1  |  980  |\n",
      "| 1 |  0  | 1102 |  2  |  2  |  1  |  1  |  5  |  2  |  20 |  0  |  1135 |\n",
      "| 2 |  15 |  64  | 807 |  23 |  16 |  0  |  43 |  24 |  39 |  1  |  1032 |\n",
      "| 3 |  4  |  18  |  30 | 876 |  2  |  14 |  8  |  24 |  20 |  14 |  1010 |\n",
      "| 4 |  0  |  23  |  8  |  1  | 866 |  3  |  12 |  1  |  12 |  56 |  982  |\n",
      "| 5 |  16 |  17  |  10 |  94 |  18 | 602 |  24 |  21 |  66 |  24 |  892  |\n",
      "| 6 |  17 |  9   |  13 |  0  |  21 |  16 | 873 |  0  |  9  |  0  |  958  |\n",
      "| 7 |  5  |  38  |  16 |  11 |  17 |  0  |  2  | 885 |  4  |  50 |  1028 |\n",
      "| 8 |  16 |  55  |  8  |  35 |  27 |  43 |  19 |  14 | 733 |  24 |  974  |\n",
      "| 9 |  18 |  12  |  4  |  16 |  62 |  0  |  2  |  62 |  8  | 825 |  1009 |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Table with 512 parameters\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1   |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "| 0 | 941 |  0   |  2  |  2  |  1  |  8  |  15 |  2  |  7  |  2  |  980  |\n",
      "| 1 |  0  | 1105 |  2  |  2  |  1  |  1  |  5  |  2  |  17 |  0  |  1135 |\n",
      "| 2 |  18 |  61  | 812 |  26 |  16 |  0  |  37 |  18 |  39 |  5  |  1032 |\n",
      "| 3 |  4  |  15  |  22 | 890 |  2  |  16 |  10 |  21 |  19 |  11 |  1010 |\n",
      "| 4 |  0  |  22  |  6  |  2  | 871 |  4  |  9  |  1  |  15 |  52 |  982  |\n",
      "| 5 |  21 |  16  |  6  |  87 |  17 | 623 |  20 |  13 |  67 |  22 |  892  |\n",
      "| 6 |  19 |  10  |  11 |  0  |  20 |  17 | 872 |  0  |  9  |  0  |  958  |\n",
      "| 7 |  4  |  37  |  17 |  8  |  21 |  1  |  1  | 879 |  4  |  56 |  1028 |\n",
      "| 8 |  17 |  53  |  10 |  31 |  26 |  40 |  16 |  13 | 746 |  22 |  974  |\n",
      "| 9 |  18 |  11  |  4  |  15 |  68 |  0  |  1  |  78 |  12 | 802 |  1009 |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n",
      "Confusion Table with 1024 parameters\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|   |  0  |  1   |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | Total |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "| 0 | 942 |  0   |  2  |  2  |  1  |  7  |  15 |  2  |  7  |  2  |  980  |\n",
      "| 1 |  0  | 1107 |  2  |  2  |  1  |  1  |  5  |  2  |  15 |  0  |  1135 |\n",
      "| 2 |  17 |  56  | 809 |  28 |  16 |  0  |  42 |  21 |  39 |  4  |  1032 |\n",
      "| 3 |  4  |  15  |  26 | 887 |  2  |  14 |  9  |  21 |  21 |  11 |  1010 |\n",
      "| 4 |  0  |  23  |  6  |  3  | 872 |  5  |  10 |  2  |  13 |  48 |  982  |\n",
      "| 5 |  20 |  17  |  2  |  84 |  19 | 624 |  22 |  13 |  69 |  22 |  892  |\n",
      "| 6 |  17 |  9   |  10 |  0  |  21 |  20 | 872 |  0  |  9  |  0  |  958  |\n",
      "| 7 |  5  |  38  |  18 |  8  |  20 |  0  |  1  | 877 |  3  |  58 |  1028 |\n",
      "| 8 |  17 |  54  |  9  |  32 |  27 |  42 |  15 |  12 | 743 |  23 |  974  |\n",
      "| 9 |  18 |  10  |  2  |  15 |  72 |  1  |  1  |  77 |  13 | 800 |  1009 |\n",
      "+---+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_paras = [2**n for n in range(1, 11)]\n",
    "\n",
    "f1_history = []\n",
    "\n",
    "for p in num_paras:\n",
    "    confusion, f1 = classificate(p,\n",
    "        list_image_train, num_train, list_label_train,\n",
    "        list_image_test, num_test, list_label_test)\n",
    "    \n",
    "    f1_history.append(round(f1, 4))\n",
    "    \n",
    "    print('Confusion Table with {} parameters'.format(p))\n",
    "    print_table(confusion)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------+--------+-------+--------+--------+--------+--------+--------+\n",
      "|  2  |   4    |   8    |   16   |   32  |   64   |  128   |  256   |  512   |  1024  |\n",
      "+-----+--------+--------+--------+-------+--------+--------+--------+--------+--------+\n",
      "| nan | 0.2482 | 0.3999 | 0.5342 | 0.692 | 0.7847 | 0.8386 | 0.8474 | 0.8512 | 0.8503 |\n",
      "+-----+--------+--------+--------+-------+--------+--------+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"F1 Score History\")\n",
    "plt.plot(num_paras, f1_history, 'b-')\n",
    "plt.xlabel('number of parameters')\n",
    "plt.ylabel('F1 score')\n",
    "plt.show()\n",
    "\n",
    "t = PrettyTable(num_paras)\n",
    "t.add_row(f1_history)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When number of parameters is small, sometimes we cannot even get valid $F_{1}$ score, because True Positive and False Posive can both be zero.\n",
    "\n",
    "When have 128 parameters, we almost get one of the best score, after that point $F_{1}$ score still increases but not changes much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
